\chapter{Background \& Theory} \label{chap_theory}

\section{Security Context}

Information security in practice revolves around three key goals colloquially known as the `CIA Triad' \cite{krutz2010cloudsec}:

\begin{itemize}
	\item Ensuring information is appropriately \textit{Confidential}

	\begin{itemize}
		\item Example: a secret password being leaked is a confidentiality violation
	\end{itemize}
	
	\item Ensuring information has \textit{Integrity}
	
	\begin{itemize}
		\item Example: a database being accessed and records falsified is an integrity violation
	\end{itemize}
	
	\item Ensuring information is \textit{Available}
	
	\begin{itemize}
		\item Example: a Denial of Service (DoS) attack causing a website to crash is an availability violation
	\end{itemize}

\end{itemize}

Most language-based security features focus on the confidentiality and integrity of information; that is, ensuring that secret information remains secret, and that information which needs to be trusted is, in fact, trustworthy.

The most common mechanism used in computer systems to ensure confidentiality and integrity is \textit{access control}: associating some `permissions' with users of a system and restricting the actions they are able to perform based on these permissions.

\section{The Java Security Model}

The Java programming language was designed in the context of emerging internet technologies, with the explict use case of users downloading and running `applets' from web pages. As such, security was a core consideration of Java's design -- the original design goals document \cite{javadesignprinciples} specifies that ``applications written in the Java programming language are secure from intrusion by unauthorized code."

Java is type safe and memory safe, which reduces the possibility of programmer error leading to exploitable flaws in an application. Java's application sandbox takes a three-pronged approach to security in the context of applets which may be downloaded from a remote server, with the Bytecode Verifier, the Class Loader, and the Security Manager \cite{mcgraw1999securingjava}.

The Bytecode Verifier and the Class Loader concern the loading of new classes into a running Java Virtual Machine (JVM). The Bytecode Verifier analyses the class to ensure it maintains the class format, does not perform illegal casts, and that it obeys Java's typing rules more generally (e.g. that private methods may not be accessed outside of a class, final methods may not be overridden) \cite{lindholm2014java}. The Class Loader performs the actual loading of a class into the JVM; the `primordial' Class Loader \cite{mcgraw1999securingjava} loads the Java API classes, and other classes may be loaded by a user-specified \mono{ClassLoader} instance.

\subsection{The Security Manager \& Stack Inspection}

The final element of the sandbox model is the \mono{SecurityManager} class. When enabled, an instance of \mono{SecurityManager} runs in the JVM, and performs runtime access control: when a potentially sensitive action is undertaken, the Security Manager checks the permissions of the calling class based on the system policy (usually specified by an external policy file), and throws an exception if the permission check fails \cite{gosling2014java}.

Permission checks are performed using stack inspection \cite{gong2003javasecurity}: every frame on the call stack below the sensitive operation is examined, and if \textit{any} frame does not have the required permissions, the check fails. Java provides the \mono{doPrivileged} construct to bypass full stack inspection \cite{gong2003javasecurity} where this is desired functionality.

\section{Information Flow Security}

Access control mechanisms limit the \textit{permissions} of a subject attempting to access data. Many programs and operating systems make use of \textit{Discretionary} Access Control, which models permission via Access Control Lists specifying what items individual users or groups of users may access (for example: the Unix permissions system). What such mechanisms cannot restrict is the way in which information \textit{propagates}.

Under Discretionary Access Control, only authorised users may access a piece of data. But once access is given, there are no controls on what the user may do with it. \textit{Information Flow} mechanisms seek to improve this, by enforcing some policy on the data itself, so even if a user may \textit{access} the data, there are restrictions on how they may propagate that data.

\section{Mandatory Access Control \& The Lattice Model}

The most well-known model designed to deal with Information Flow security, Mandatory Access Control (MAC), is most commonly associated with the military and other high-security organisations. In a MAC system, all data has a \textit{classification}, and users operate with a \textit{clearance}. 

In the simplest case, the set of classifications is just an ordered list -- for instance, `Unclassified' $ < $ `Classified' $ < $ `Secret' $ < $ `Top Secret'. A user with `Secret' clearance, then, cannot access or modify `Top Secret' documents.

More flexible access control policies may be implemented under the Bell-Lapadula lattice model \cite{bell1973lattice}, which is at the heart of most modern MAC systems. Under this model, classifications form a \textit{lattice} -- a set partially ordered by a flow relation (written $ \succeq $) where, for every possible pair of elements, a `least upper bound' (or `join', written $ \sqcup $) and `greatest lower bound' (or `meet', written $ \sqcap $) may be found.

In the MAC context, for policies in a lattice structure it is always possible to determine whether a user at clearance $ A $ can access information at classification $ B $ -- they can if $ B \succeq A $. Given any two classifications $ A $ and $ B $, one can find the least restrictive classification which enforces both, $ A \sqcup B $, and the most restrictive classification which users at either clearance $ A $ or $ B $ can read, $ A \sqcap B $.

MAC is applied to the an access control problem concerning users (or `subjects') and classified documents (or `objects') via two key rules \cite{sandhu1993lattice}:

\begin{description}
	\item[Simple Security Property -- `No Read Up'] A subject with clearance $ C_s $ may access an object with classification $ C_o $ if and only if $ C_s \succeq C_o $
	
	\item[* Property -- `No Write Down'] A subject with clearance $ C_s $ may only modify an object with classification $ C_o $ if $ C_o \succeq C_s $
\end{description}

The Simple Security Property prevents users with insufficient clearance from accessing highly classified data. But the * Property is also important: it states that a user with high clearance cannot modify data at a low classification. This prevents a highly privileged user from declassifying data by copying it to a document with lower classification, thereby introducing a control on the \textit{propagation} of that information.

Lattice-based Mandatory Access Control may be applied to computer systems, just as to physical documents. Such systems generally use a `high water mark' approach \cite{jones1975highwatermark}, allowing programs to begin at low clearance and only moving to higher clearance as needed.

\section{Formal Non-interference} \label{theory_if_noninterference}

The traditional MAC model may be implemented in a real system via runtime-enforced access control checks. However, the fundamental question remains: how does the program's author know whether it's implemented \textit{correctly}? Many security issues are the result of unintentional programmer error, and so it is useful to approach Information Flow security from the perspective of program verification.

This goal can be more clearly defined through the notion of `non-interference'. A program is said to be non-interfering if, given any two program executions which are identical in terms of their low confidentiality input, the results and behaviour of the executions are indistinguishable \cite{sabelfeld2003if}. This notion may be formalised by the definition that a program is non-interfering if there is no \textit{dependency} of low confidentiality data on high confidentiality data \cite{cohen1977declassification}.

In \citetitle{denning1977certification}, \citeauthor{denning1977certification} \cite{denning1977certification} provide a mechanism which can verify a program as correctly respecting a MAC policy using type checking: all variables are assigned a classification, and the analyser ensures that the policy is not broken under any execution path. A language which makes use of type checking-based flow verification is considered a \textit{security typed} language.

The type checker's semantics prevent high confidentiality information moving to a lower classification. So, for instance, the following code would be invalid:

\begin{algorithmic}
\State $ high := 1 $
\State $ low := high $
\end{algorithmic}

Clearly, assigning the value of a high confidentiality variable to a variable with low confidentiality violates the policy, and in a non-interference sense allows an attacker with low confidentiality privileges to learn the high confidentiality value.

\subsection{Implicit Flows}

\citeauthor{denning1977certification} \cite{denning1977certification} categorise the flows of information within a program into \textit{explicit} and \textit{implicit} flows. An explicit flow $ x \rightarrow y $ is one such as an assignment $ y := x $, where the operation performed is independent of the actual value of $ x $. An implicit flow $ x \rightarrow y $ is then any arbitrary flow $ z \rightarrow y $ where the execution depends on the value of $ x $. 

A simple example of an implicit flow causing an information leak is one where execution branches based on the value of a high confidentiality variable:

\begin{algorithmic}
	\State $ high := 0 $
	\State $ low := 0 $
	\If {$ high = 5 $}
		\State $ low := 1 $
	\Else
		\State $ low := 0 $
	\EndIf
\end{algorithmic}

Here, someone with access to the $ low $ variable knows that $ low $ will only have the value $ 1 $ if $ high $ has the value $ 5 $. After this code executes, they can see that $ low = 0 $, and therefore $ high \ne 5 $. They do not know the actual value of $ high $ but they have still learned some information about it.

For a program to be non-interfering, a passive attacker must not be able to distinguish \textit{any} information about high confidentiality data; hence implicit flows which allow an attacker to learn high confidentiality information must be prevented \cite{sabelfeld2003if}.


To handle implicit flow of confidentiality via the flow of control, the type checker must consider the confidentiality of the execution \textit{context}. The above snippet's if statement represents a `high context' where assignments to low confidentiality variables is impermissible.

\subsection{Undecidability in the General Case}

The type checking approach to proving non-interference is necessarily conservative: there will always be some programs which are non-interfering which will nonetheless be rejected by the static analysis. This goes beyond being a limitation of current models: determining a condition which is both necessary and sufficient for a program to be non-interfering is an undecidable problem \cite{denning1977certification} \cite{landi1992undecidability} -- it may be reduced to the halting problem \cite{sabelfeld2003if}.

%This can be seen quite intuitively. Let $ S $ be an arbitrary procedure which affects only low confidentiality variables, and then consider the following \cite{sabelfeld2003if}:
%
%\begin{algorithmic}
%	\If {$ high = 1 $}
%	\State $ S() $
%	\State $ low := 1 $
%	\Else
%	\State skip
%	\EndIf
%\end{algorithmic}

%Determining whether this program actually produces an invalid flow from $ high \rightarrow low $ requires proving that the procedure call $ S() $ will terminate. By this reduction, proving a program's non-interference in the general case may be reduced to the halting problem \cite{denning1977certification}.

In practice, systems for statically analysing information flow attempt to ensure that they reject as few \textit{useful} valid programs as is feasible.

\subsection{Covert Channels \& Attacker Model}

Consider the following program:

\begin{algorithmic}
	\State $ low := 0 $
	\If {$ high = 5 $}
		\For{$ i := 1 $ \textbf{to} $ 1000000000 $}
			\State skip
		\EndFor
	\Else
		\State skip
	\EndIf
\end{algorithmic}

By the conventional definitions of information flow, considering both explicit and implicit flows, this program is non-interfering: the value of $ low $ does not in any way depend on the value of $ high $. Yet, someone observing this programs output would be able to learn information about the value of $ high $: the program will clearly take significantly longer to execute in the case where $ high = 5 $.

A program can only be considered secure \textit{with respect to its environment} \cite{sabelfeld2003if}, and the standard construction of non-interference does not consider the timing of a program as a channel for the transmission of information; hence, this kind of information leak is considered a `covert channel' leak.

\citeauthor{sabelfeld2003if} \cite{sabelfeld2003if} address a number of possible covert channels which impact on information flow analysis, including timing channels like the above, termination-sensitivity (i.e. whether a program terminates at all), system power usage, and probabilistic channels for programs with stochastic behaviour. Notions of non-interference which examine these channels may be constructed, though doing so will further restrict the potential acceptable programs which may be written.

Hence, proving a program's non-interference through static checking is not a panacea: a program's environment and attacker model must still be considered. In some contexts, `timing-sensitive' non-interference may be necessary, but enforcing that a program will never differ in execution time based on high confidentiality information has quite obvious drawbacks in the performance of a valid program and in the kinds of programs which may be written.

\section{Declassification}

A program which is provably non-interfering provides useful guarantees around a program's behaviour: in the military context for which MAC was designed, it ensures that a program running in a high confidentiality environment cannot as a matter of course declassify information to a lower level. However, in most contexts, requiring strict non-interference prevents useful and necessary programs from being written.

One example of this is a `password checker' program. The true value of the password is confidential, and the user must provide a correct guess in order to log in. Clearly the operation of the program depends on the value of the high confidentiality password, and a user attempting to log in learns some information about it -- even if rejected, the user has learned that the true password is \textit{not} equal to their guess.

A password checker is interfering by design: it has to give feedback on whether the user's guess matches the true password. But this does not violate the desired security properties, since the search space for possible passwords is large, and the user may only guess one at a time.

Rejecting \textit{all} interfering programs makes it very difficult to write even simple programs like a password checker. Hence, security typed languages provide `declassification' mechanisms to allow interference, but only when a programmer explicitly declares it.

\subsection{Selective Declassification}

Selective declassification mechanisms provide an `escape hatch' from the security typing system. 

\subsection{Alternate Approaches to `Dynamic' Policy}

\section{Enforcement}

\subsection{Statically Enforced Models}

DENNING

DLM

PARAGON

\subsection{Runtime Enforced Models}




%\section{The Decentralised Label Model}
%
%\section{Logic-Based Policies \& The Paralock Model}
%
%\section{Other Models}


%** MOVED FROM COMPARISON... **
%
%The `JFlow' language, through both the paper \cite{myers1999jflow} that proposed it and its subsequent implementation as Java Information Flow (JIF), has become the dominant language and the dominant paradigm in security typing and static information flow control languages more generally.
%
%As articulated by \citeauthor{broberg2013paragon} in \citetitle{broberg2013paragon} \cite{broberg2013paragon}, JIF may be regarded as a `second-generation Information Flow language'. Its Decentralised Label Model allowed for more flexible and more useful policies to be expressed than the straight Mandatory Access Control lattice that had been at the centre of most prior work, and its implementation as an extension of the popular Java language made it comparatively practical to work with.
%
%Under this taxonomy, Paragon is then a `third-generation Information Flow language'. It discards lattice-based policy definition entirely in favour of policies which may defined through logical expressions. This abstraction, combined with the Paralock construct which allows for policies which model relations and which vary over the lifetime of a running program, broadens the scope of what security requirements can be expressed.
%
%The Paralock construct which Paragon introduces allow for policies which vary over the lifetime of a running program, something which cannot be represented effectively under JIF's policy model. In addition, Paralocks can model relations between actors of arity zero, one or two, and through the use of binary relations, the Decentralised Label Model can in fact be written within Paragon's policy language. That is, JIF's policy mechanism can be encoded using Paragon's.