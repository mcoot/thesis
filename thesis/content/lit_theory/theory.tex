\chapter{Background \& Theory} \label{chap_theory}

\section{Security Context}

Information security in practice revolves around three key goals colloquially known as the `CIA Triad' \cite{krutz2010cloudsec}:

\begin{itemize}
	\item Ensuring information is appropriately \textit{Confidential}

	\begin{itemize}
		\item Example: a secret password being leaked is a confidentiality violation
	\end{itemize}
	
	\item Ensuring information has \textit{Integrity}
	
	\begin{itemize}
		\item Example: a database being accessed and records falsified is an integrity violation
	\end{itemize}
	
	\item Ensuring information is \textit{Available}
	
	\begin{itemize}
		\item Example: a Denial of Service (DoS) attack causing a website to crash is an availability violation
	\end{itemize}

\end{itemize}

Most language-based security features focus on the confidentiality and integrity of information; that is, ensuring that secret information remains secret, and that information which needs to be trusted is, in fact, trustworthy.

The most common mechanism used in computer systems to ensure confidentiality and integrity is \textit{access control}: associating some `permissions' with users of a system and restricting the actions they are able to perform based on these permissions.

\section{The Java Security Model}

The Java programming language was designed in the context of emerging internet technologies, with the explict use case of users downloading and running `applets' from web pages. As such, security was a core consideration of Java's design -- the original design goals document \cite{javadesignprinciples} specifies that ``applications written in the Java programming language are secure from intrusion by unauthorized code."

Java is type safe and memory safe, which reduces the possibility of programmer error leading to exploitable flaws in an application. Java's application sandbox takes a three-pronged approach to security in the context of applets which may be downloaded from a remote server, with the Bytecode Verifier, the Class Loader, and the Security Manager \cite{mcgraw1999securingjava}.

The Bytecode Verifier and the Class Loader concern the loading of new classes into a running Java Virtual Machine (JVM). The Bytecode Verifier analyses the class to ensure it maintains the class format, does not perform illegal casts, and that it obeys Java's typing rules more generally (e.g. that private methods may not be accessed outside of a class, final methods may not be overridden) \cite{lindholm2014java}. The Class Loader performs the actual loading of a class into the JVM; the `primordial' Class Loader \cite{mcgraw1999securingjava} loads the Java API classes, and other classes may be loaded by a user-specified \mono{ClassLoader} instance.

\subsection{The Security Manager \& Stack Inspection}

The final element of the sandbox model is the \mono{SecurityManager} class. When enabled, an instance of \mono{SecurityManager} runs in the JVM, and performs runtime access control: when a potentially sensitive action is undertaken, the Security Manager checks the permissions of the calling class based on the system policy (usually specified by an external policy file), and throws an exception if the permission check fails \cite{gosling2014java}.

Permission checks are performed using stack inspection \cite{gong2003javasecurity}: every frame on the call stack below the sensitive operation is examined, and if \textit{any} frame does not have the required permissions, the check fails. Java provides the \mono{doPrivileged} construct to bypass full stack inspection \cite{gong2003javasecurity} where this is desired functionality.

\section{Information Flow Security}

Access control mechanisms limit the \textit{permissions} of a subject attempting to access data. Many programs and operating systems make use of \textit{Discretionary} Access Control, which models permission via Access Control Lists specifying what items individual users or groups of users may access (for example: the Unix permissions system). What such mechanisms cannot restrict is the way in which information \textit{propagates}.

Under Discretionary Access Control, only authorised users may access a piece of data. But once access is given, there are no controls on what the user may do with it. \textit{Information Flow} mechanisms seek to improve this, by enforcing some policy on the data itself, so even if a user may \textit{access} the data, there are restrictions on how they may propagate that data.

\section{Mandatory Access Control \& The Lattice Model}

The most well-known model designed to deal with Information Flow security, Mandatory Access Control (MAC), is most commonly associated with the military and other high-security organisations. In a MAC system, all data has a \textit{classification}, and users operate with a \textit{clearance}. 

In the simplest case, the set of classifications is just an ordered list -- for instance, `Unclassified' $ < $ `Classified' $ < $ `Secret' $ < $ `Top Secret'. A user with `Secret' clearance, then, cannot access or modify `Top Secret' documents.

More flexible access control policies may be implemented under the Bell-Lapadula lattice model \cite{bell1973lattice}, which is at the heart of most modern MAC systems. Under this model, classifications form a \textit{lattice} -- a set partially ordered by a flow relation (written $ \succeq $) where, for every possible pair of elements, a `least upper bound' (or `join', written $ \sqcup $) and `greatest lower bound' (or `meet', written $ \sqcap $) may be found.

In the MAC context, for policies in a lattice structure it is always possible to determine whether a user at clearance $ A $ can access information at classification $ B $ -- they can if $ B \succeq A $. Given any two classifications $ A $ and $ B $, one can find the least restrictive classification which enforces both, $ A \sqcup B $, and the most restrictive classification which users at either clearance $ A $ or $ B $ can read, $ A \sqcap B $.

MAC is applied to the an access control problem concerning users (or `subjects') and classified documents (or `objects') via two key rules \cite{sandhu1993lattice}:

\begin{description}
	\item[Simple Security Property -- `No Read Up'] A subject with clearance $ C_s $ may access an object with classification $ C_o $ if and only if $ C_s \succeq C_o $
	
	\item[* Property -- `No Write Down'] A subject with clearance $ C_s $ may only modify an object with classification $ C_o $ if $ C_o \succeq C_s $
\end{description}

The Simple Security Property prevents users with insufficient clearance from accessing highly classified data. But the * Property is also important: it states that a user with high clearance cannot modify data at a low classification. This prevents a highly privileged user from declassifying data by copying it to a document with lower classification, thereby introducing a control on the \textit{propagation} of that information.

Lattice-based Mandatory Access Control may be applied to computer systems, just as to physical documents. Such systems generally use a `high water mark' approach \cite{jones1975highwatermark}, allowing programs to begin at low clearance and only moving to higher clearance as needed.

\section{Formal Non-interference} \label{theory_if_noninterference}

The traditional MAC model may be implemented in a real system via runtime-enforced access control checks. However, the fundamental question remains: how does the program's author know whether it's implemented \textit{correctly}? Many security issues are the result of unintentional programmer error, and so it is useful to approach Information Flow security from the perspective of program verification.

This goal can be more clearly defined through the notion of `non-interference'. A program is said to be non-interfering if, given any two program executions which are identical in terms of their low confidentiality input, the results and behaviour of the executions are indistinguishable \cite{sabelfeld2003if}. This notion may be formalised by the definition that a program is non-interfering if there is no \textit{dependency} of low confidentiality data on high confidentiality data \cite{cohen1977declassification}.

In \citetitle{denning1977certification}, \citeauthor{denning1977certification} \cite{denning1977certification} provide a mechanism which can verify a program as correctly respecting a MAC policy using type checking: all variables are assigned a classification, and the analyser ensures that the policy is not broken under any execution path.

The type checker's semantics prevent high confidentiality information moving to a lower classification. So, for instance, the following code would be invalid:

\begin{algorithmic}
\State $ high := 1 $
\State $ low := high $
\end{algorithmic}

Clearly, assigning the value of a high confidentiality variable to a variable with low confidentiality violates the policy, and in a non-interference sense allows an attacker with low confidentiality privileges to learn the high confidentiality value.

\subsection{Implicit Flows}

\citeauthor{denning1977certification} \cite{denning1977certification} categorise the flows of information within a program into \textit{explicit} and \textit{implicit} flows. An explicit flow $ x \rightarrow y $ is one such as an assignment $ y := x $, where the operation performed is independent of the actual value of $ x $. An implicit flow $ x \rightarrow y $ is then any arbitrary flow $ z \rightarrow y $ where the execution depends on the value of $ x $. 

A simple example of an implicit flow causing an information leak is one where execution branches based on the value of a high confidentiality variable:

\begin{algorithmic}
	\State $ high := 0 $
	\State $ low := 0 $
	\If {$ high = 5 $}
	\State $ low := 1 $
	\Else
	\State $ low := 0 $
	\EndIf
\end{algorithmic}

Here, someone with access to the $ low $ variable knows that $ low $ will only have the value $ 1 $ if $ high $ has the value $ 5 $. After this code executes, they can see that $ low = 0 $, and therefore $ high \ne 5 $. They do not know the actual value of $ high $ but they have still learned some information about it.

For a program to be non-interfering, a passive attacker must not be able to distinguish \textit{any} information about high confidentiality data; hence implicit flows which allow an attacker to learn high confidentiality information must be prevented \cite{sabelfeld2003if}.


To handle implicit flow of confidentiality via the flow of control, the type checker must consider the confidentiality of the execution \textit{context}. The above snippet's if statement represents a `high context' where assignments to low confidentiality variables is impermissible.

\subsection{Undecidability in the General Case}

\subsection{Covert Channels \& Attacker Model}

\section{Declassification}

\section{Enforcement}

\subsection{Statically Enforced Models}

DENNING

DLM

PARAGON

\subsection{Runtime Enforced Models}




%\section{The Decentralised Label Model}
%
%\section{Logic-Based Policies \& The Paralock Model}
%
%\section{Other Models}


%** MOVED FROM COMPARISON... **
%
%The `JFlow' language, through both the paper \cite{myers1999jflow} that proposed it and its subsequent implementation as Java Information Flow (JIF), has become the dominant language and the dominant paradigm in security typing and static information flow control languages more generally.
%
%As articulated by \citeauthor{broberg2013paragon} in \citetitle{broberg2013paragon} \cite{broberg2013paragon}, JIF may be regarded as a `second-generation Information Flow language'. Its Decentralised Label Model allowed for more flexible and more useful policies to be expressed than the straight Mandatory Access Control lattice that had been at the centre of most prior work, and its implementation as an extension of the popular Java language made it comparatively practical to work with.
%
%Under this taxonomy, Paragon is then a `third-generation Information Flow language'. It discards lattice-based policy definition entirely in favour of policies which may defined through logical expressions. This abstraction, combined with the Paralock construct which allows for policies which model relations and which vary over the lifetime of a running program, broadens the scope of what security requirements can be expressed.
%
%The Paralock construct which Paragon introduces allow for policies which vary over the lifetime of a running program, something which cannot be represented effectively under JIF's policy model. In addition, Paralocks can model relations between actors of arity zero, one or two, and through the use of binary relations, the Decentralised Label Model can in fact be written within Paragon's policy language. That is, JIF's policy mechanism can be encoded using Paragon's.